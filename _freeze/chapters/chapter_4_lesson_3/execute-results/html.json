{
  "hash": "a5a8cd930eacfbfdb213fbfd602f9273",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Autoregressive (AR) Models\"\nsubtitle: \"Chapter 4: Lesson 3\"\nformat: \n  html:\n    error: false\n    message: false\n    warning: false\n    embed-resources: true\n    toc: true\n    code-fold: true\n---\n\n\n\n\n\n## Lesson 4.3 Autoregressive (AR) Models\n\n### Properties of an AR(p) Stochastic Process\n\n\n### Definition of Autoregressive (AR) Models\n\n-  **Autoregressive (AR) Models Lesson 4.3**\n    -   An AR is a linear regression model that uses lagged values of the time series to predict future values.\n    -   An AR is a stochastic process that uses a linear combination of past values of the time series to predict future values.\n\n\n::: {.callout-note icon=\"false\" title=\"Definition of an Autoregressive (AR) Model\"}\nThe time series $\\{x_t\\}$ is an **autoregressive process of order** $p$, denoted as $AR(p)$, if \n$$\n  x_t = \\alpha_1 x_{t-1} + \\alpha_2 x_{t-2} + \\alpha_3 x_{t-3} + \\cdots + \\alpha_{p-1} x_{t-(p-1)} + \\alpha_p x_{t-p} + w_t ~~~~~~~~~~~~~~~~~~~~~~~ (4.15)\n$$\n\nwhere $\\{w_t\\}$ is white noise and the $\\alpha_i$ are the model parameters with $\\alpha_p \\ne 0$.\n:::\n\n**Autoregressive Properties of an AR model**\n\n-  The mean of an AR model is a constant.\n-  The variance of an AR model is finite.\n-  The covariance of an AR model is a function of the lag.\n-  The autocorrelation of an AR model is a function of the lag.\n\n\n### Exploring AR(1) Models\n\n**Definitino**\nRecall that an $AR(p)$ model is of the form $$\n  x_t = \\alpha_1 x_{t-1} + \\alpha_2 x_{t-2} + \\alpha_3 x_{t-3} + \\cdots + \\alpha_{p-1} x_{t-(p-1)} + \\alpha_p x_{t-p} + w_t\n$$ So, an $AR(1)$ model is expressed as $$\n  x_t = \\alpha x_{t-1} + w_t\n$$ where $\\{w_t\\}$ is a white noise series with mean zero and variance $\\sigma^2$.\n\n\n\n### Second-Order Properties of an AR(1) Model\n\n:::: {.callout-note icon=\"false\" title=\"Second-Order Properties of an $AR(1)$ Model\"}\nIf $\\{x_t\\}_{t=1}^n$ is an $AR(1)$ prcess, then its the first- and second-order properties are summarized below.\n\n$$\n\\begin{align*}\n  \\mu_x &= 0 \\\\  \n  \\gamma_k = cov(x_t, x_{t+k}) &= \\frac{\\alpha^k \\sigma^2}{1-\\alpha^2}\n\\end{align*}\n$$\n\n::: {.callout-tip title=\"Click here for a proof of the equation for $cov(x_t,x_{t+k})$\" collapse=\"true\"}\nWhy is $cov(x_t, x_{t+k}) = \\dfrac{\\alpha^k \\sigma^2}{1-\\alpha^2}$?\n\nIf $\\{x_t\\}$ is a stable $AR(1)$ process (which means that \\$\\|\\alpha\\|\\<1) can be written as:\n\n\\begin{align*}\n  (1-\\alpha \\mathbf{B}) x_t &= w_t \\\\\n  \\implies x_t &= (1-\\alpha \\mathbf{B})^{-1} w_t \\\\\n    &= w_t + \\alpha w_{t-1} + \\alpha^2 w_{t-2} + \\alpha^3 w_{t-3} + \\cdots \\\\\n    &= \\sum\\limits_{i=0}^\\infty \\alpha^i w_{t-i}\n\\end{align*}\n\nFrom this, we can deduce that the mean is\n\n$$\n  E(x_t) \n    = E\\left( \\sum\\limits_{i=0}^\\infty \\alpha^i w_{t-i} \\right)\n    = \\sum\\limits_{i=0}^\\infty \\alpha^i E\\left( w_{t-i} \\right)\n    = 0\n$$\n\nThe autocovariance is computed similarly as:\n\n\\begin{align*}\n  \\gamma_k = cov(x_t, x_{t+k}) \n    &= cov \\left( \n      \\sum\\limits_{i=0}^\\infty \\alpha^i w_{t-i}, \\\\\n      \\sum\\limits_{j=0}^\\infty \\alpha^j w_{t+k-j} \\right) \\\\\n    &= \\sum\\limits_{j=k+i} \\alpha^i \\alpha^j cov ( w_{t-i}, w_{t+k-j} ) \\\\\n    &= \\alpha^k \\sigma^2 \\sum\\limits_{i=0}^\\infty \\alpha^{2i} \\\\\n    &= \\frac{\\alpha^k \\sigma^2}{1-\\alpha^2}\n\\end{align*}\n\nSee Equations (2.15) and (4.2).\n:::\n::::\n\n### Correlogram of an AR(1) Model\n\n-  The autocorrelation function of an $AR(1)$ model is a function of the lag.\n\n::: {.callout-note icon=\"false\" title=\"Correlogram of an AR(1) Process\"}\nThe autocorrelation function for an AR(1) process is\n\n$$\n  \\rho_k = \\alpha^k ~~~~~~ (k \\ge 0)\n$$ where $|\\alpha| < 1$.\n:::\n\n\n**Things to do** \n- DO group activity: Simulation of an AR(1) process\n\n\n### Partial Autocorrelation\n\n::: {.callout-note icon=\"false\" title=\"Definition: Partial Autocorrleation\"}\nThe **partial autocorrelation** at lag $k$ is defined as the portion of the correlation that is not explained by shorter lags.\n:::\n\nFor example, the partial correlation for lag 4 is the correlation not explained by lags 1, 2, or 3.\n\n\n::: {.callout-tip icon=\"false\" title=\"Check Your Understanding\"}\n-   What is the value of the partial autocorrelation function for an $AR(2)$ process for all lags greater than 2? answer: 0\n:::\n\n\n\n### Example: McDonald's Stock Price\n\nHere is a partial autocorrelation plot for the McDonald's stock price data:\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Loading R packages\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(tidyverse,\n               tsibble, fable,\n               feasts, tsibbledata,\n               fable.prophet,\n               patchwork,\n               lubridate,\n               rio,\n               ggplot2,\n               kableExtra\n               )\n\n# Set symbol and date range\nsymbol <- \"MCD\"\ncompany <- \"McDonald's\"\n\n# Retrieve static file\nstock_df <- rio::import(\"https://byuistats.github.io/timeseries/data/stock_price_mcd.parquet\")\n\n# Transform data into tibble\nstock_ts <- stock_df %>%\n  mutate(\n    dates = date, \n    value = adjusted\n  ) %>%\n  select(dates, value) %>%\n  as_tibble() %>% \n  arrange(dates) |>\n  mutate(diff = value - lag(value)) |>\n  as_tsibble(index = dates, key = NULL) \n\npacf(stock_ts$value, plot=TRUE, lag.max = 25)\n```\n\n::: {.cell-output-display}\n![](chapter_4_lesson_3_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n\nThe only significant partial correlation is at lag $k=1$. This suggests that an $AR(1)$ process could be used to model the McDonald's stock prices.\n\n\n\n\n### Partial Autocorrelation Plots of Various AR(p) Processes\n\n**Look at lesson shinny code**\n\n\n\n### Sationary and Non-Stationary AR Processes\n\n::: {.callout-note icon=\"false\" title=\"Definition of the Characteristic Equation\"}\nTreating the symbol $\\mathbf{B}$ formally as a number (either real or complex), the polynomial\n\n$$\n  \\theta_p(\\mathbf{B}) x_t = \\left( 1 - \\alpha_1 \\mathbf{B} - \\alpha_2 \\mathbf{B}^2 - \\cdots - \\alpha_p \\mathbf{B}^p \\right) x_t\n$$\n\nis called the **characteristic polynomial** of an AR process.\n\nIf we set the characteristic polynomial to zero, we get the **characteristic equation**:\n\n$$\n  \\theta_p(\\mathbf{B}) = \\left( 1 - \\alpha_1 \\mathbf{B} - \\alpha_2 \\mathbf{B}^2 - \\cdots - \\alpha_p \\mathbf{B}^p \\right) = 0\n$$\n:::\n\n\n::: {.callout-note icon=\"false\" title=\"Identifying Stationary Processes\"}\nAn AR process will be **stationary** if the absolute value of the solutions of the characteristic equation are all strictly greater than 1.\n:::\n\nFirst, we will find the roots of the characteristic polynomial (i.e. the solutions of the characteristic equation) and then we will determine if the absolute value of these solutions is greater than 1.\n\nWe can use the `polyroot` function to find the roots of polynomials in R. For example, to find the roots of the polynomial $x^2-x-6$, we apply the command\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npolyroot(c(-6,-1,1))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  3+0i -2+0i\n```\n\n\n:::\n:::\n\n\n\nNote the order of the coefficients. They are given in increasing order of the power of $x$.\n\nOf course, we could simply factor the polynomial: \n$$\n  x^2-x-6 = (x-3)(x+2) \\overset{set}{=} 0\n$$ which implies that \n$$\n  x = 3 ~~~ \\text{or} ~~~ x = -2\n$$\n\n\n\n\n### Absolute Value in the Complex Plane\n\n\n::: {.callout-note icon=\"false\" title=\"Definition of the Absolute Value in the Complex Plane\"}\nLet $z = a+bi$ be any complex number. It can be represented by the point $(a,b)$ in the complex plane. We define the absolute value of $z$ as the distance from the origin to the point:\n\n$$\n  |z| = \\sqrt{a^2 + b^2}\n$$\n:::\n\n\n**This sections check for this**\n- We will now practice assessing whether an AR process is stationary using the characteristic equation.\n\n\nco-pilot notes\n\n-  **Stationary and Non-Stationary AR Processes Lesson 4.3**\n    -   An AR process will be stationary if the absolute value of the solutions of the characteristic equation are all strictly greater than 1.\n    -   The characteristic equation of an AR process is the polynomial $\\theta_p(\\mathbf{B}) = 1 - \\alpha_1 \\mathbf{B} - \\alpha_2 \\mathbf{B}^2 - \\cdots - \\alpha_p \\mathbf{B}^p$.\n    -   The roots of the characteristic polynomial are the solutions of the characteristic equation.\n    -   The absolute value of the roots of the characteristic polynomial must be greater than 1 for the AR process to be stationary.\n\nco-pilot notes end\n\n\n\n\n\n\n\n\n\n\n### Questions\n\n* What is an exponential smoothing model?\n\n\n\n\n### Search for words for lesson 4.3 \n\nexponential smoothing model - polyroot function - ",
    "supporting": [
      "chapter_4_lesson_3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}